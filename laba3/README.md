# Лабораторная работа №3 - Отчет
## Теоретическая часть
Распознавание именованных сущностей (NER) - это задача NLP, которая включает в себя поиск и классификацию именованных сущностей (людей, мест, организаций и т.д.), упомянутых в неструктурированном тексте. 
Эта задача используется во многих приложениях NLP, которые имеют дело с такими вариантами использования, как машинный перевод, поиск информации, чат-боты и другие.

Условное случайное поле (CRF) - это статистическая модель, хорошо подходящая для решения задач NER, поскольку она учитывает контекст.
Rогда модель CRF делает прогноз, она учитывает влияние соседних выборок, моделируя прогноз в виде графической модели. 
Одна из проблем с CRF с линейной цепочкой заключается в том, что они способны фиксировать зависимости между метками только в прямом направлении. 
Если модель столкнется с таким объектом, как "Университет Джона Хопкинса", она, скорее всего, пометит токен Хопкинса в качестве имени, потому что модель 
"слепа" к токену университета, который появляется ниже по потоку.

Одним из способов решения этой проблемы является внедрение двунаправленной сети LSTM (BiLSTM) между входными данными (словами) и CRF.
Двунаправленный LSTM состоит из двух сетей LSTM - одна принимает входные данные в прямом направлении, а вторая принимает входные данные в обратном направлении. 
Объединение выходных данных двух сетей дает контекст, который предоставляет информацию о выборках, окружающих каждый отдельный токен.
Выходные данные BiLSTM затем передаются в CRF линейной цепочки, который может генерировать прогнозы, используя этот улучшенный контекст. 
Эту комбинацию CRF и BiLSTM часто называют моделью BiLSTM-CRF[1], и ее архитектура показана на рисунке ниже.

![image](https://user-images.githubusercontent.com/91135334/211100891-fff2cca9-2aaa-4baf-9603-239daec86750.png)


## Задание 1
### Задача
Участие в соревновании [2] по NER.

### Код
`lab3.ipynb` - training model
### Разработанная система

В коде была релизована система оценивания, согласно инструкциям соревнования [3],  основой которой является f1 мера. Для этого также была написана функция для преобразования данных в необходимый формат для оценки, заданный рганизаторами соревнования - for_m


Далее была реализована модель BiLSTMCRF, основанная на классах CRF  и nn.LSTM.

Затем были прочитаны данные как для обучения (train), так и оценки (valid). Для этого была написана функция read_data. Получилось следующее распредление данных:
* train -  186
* valid - 30
На основе данных был подгтовлен словарь слов и тегов. Данные также были приравнены к одной длине для дальнешейго обучения.

Затем было проведено обученение около 700  эпох. 


### Результаты

Результаты обучения представлены ниже:
![image](https://user-images.githubusercontent.com/91135334/211102888-f9e22a1b-b67c-4c8c-b71d-87835cafb822.png)


Обучение было закончено, так как метрика по которйо цоенивается соревнование(f1) перестала улучшаться. 
Наилучшее значение по f1 - 32.703%.

### Выводы
Таким образом, обучение дало значение 32.703% метрики  f1, , что является не самым худшим результатом в соревновании, но и отсатет от лучшего результата почти в половину. Возможно, дополниельные экспременты с гиперпараметрами могли бы помочь улучшить результаты, но на данный момент у меня отсуствуют вычислительные ресурсы для этого.
Также результаты можно явно улучшить дополнительной разметкой данных, которые представлены в соревновании в неразмеченном виде. 

 

## Использованные источники

[1] https://aclanthology.org/N16-1030.pdf

[2] https://github.com/dialogue-evaluation/RuREBus

[3] https://github.com/dialogue-evaluation/RuREBus/blob/master/eval_scripts/evaluate_ners.py
